{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras_metrics\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras_metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = '../data/test'\n",
    "train_folder = '../data/train'\n",
    "val_folder = '../data/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(256,256), batch_size = 627) \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(256,256), batch_size = 19)\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(256,256), batch_size=5219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 196608)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(6, (3, 3), activation='relu',\n",
    "                        input_shape=(256 ,256,  3)))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=3))\n",
    "model.add(layers.Dropout(0.75))  \n",
    "\n",
    "model.add(layers.Conv2D(12, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=3))\n",
    "model.add(layers.Dropout(0.05))  \n",
    "\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# confusion matrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/15\n",
      "5216/5216 [==============================] - 73s 14ms/step - loss: 0.3974 - acc: 0.8217 - recall: 0.4847 - val_loss: 0.5862 - val_acc: 0.7500 - val_recall: 0.5000\n",
      "Epoch 2/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.1859 - acc: 0.9241 - recall: 0.8330 - val_loss: 0.5607 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 3/15\n",
      "5216/5216 [==============================] - 87s 17ms/step - loss: 0.1402 - acc: 0.9444 - recall: 0.8867 - val_loss: 0.5102 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 4/15\n",
      "5216/5216 [==============================] - 80s 15ms/step - loss: 0.1278 - acc: 0.9544 - recall: 0.9045 - val_loss: 0.4865 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 5/15\n",
      "5216/5216 [==============================] - 79s 15ms/step - loss: 0.1081 - acc: 0.9613 - recall: 0.9202 - val_loss: 0.5257 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 6/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.1035 - acc: 0.9609 - recall: 0.9202 - val_loss: 0.3135 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 7/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.1074 - acc: 0.9601 - recall: 0.9157 - val_loss: 0.3669 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 8/15\n",
      "5216/5216 [==============================] - 75s 14ms/step - loss: 0.0836 - acc: 0.9711 - recall: 0.9403 - val_loss: 0.2725 - val_acc: 0.8750 - val_recall: 0.8750\n",
      "Epoch 9/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.0885 - acc: 0.9699 - recall: 0.9396 - val_loss: 0.2993 - val_acc: 0.8750 - val_recall: 0.8750\n",
      "Epoch 10/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.0883 - acc: 0.9657 - recall: 0.9314 - val_loss: 0.3019 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 11/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.0796 - acc: 0.9711 - recall: 0.9433 - val_loss: 0.4883 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 12/15\n",
      "5216/5216 [==============================] - 76s 15ms/step - loss: 0.0799 - acc: 0.9707 - recall: 0.9411 - val_loss: 0.3705 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 13/15\n",
      "5216/5216 [==============================] - 74s 14ms/step - loss: 0.0697 - acc: 0.9739 - recall: 0.9523 - val_loss: 0.3774 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 14/15\n",
      "5216/5216 [==============================] - 75s 14ms/step - loss: 0.0799 - acc: 0.9697 - recall: 0.9396 - val_loss: 0.4265 - val_acc: 0.9375 - val_recall: 0.8750\n",
      "Epoch 15/15\n",
      "5216/5216 [==============================] - 75s 14ms/step - loss: 0.0789 - acc: 0.9689 - recall: 0.9396 - val_loss: 0.3961 - val_acc: 0.9375 - val_recall: 0.8750\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',keras_metrics.recall()])\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=15,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 44s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 5s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2532622461304343, 0.9338573619631901, 0.9127516777842839]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4845580993554531, 0.7852564102564102, 0.5042735040580028]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4847129007841378,\n",
       " 0.8329604771936644,\n",
       " 0.8866517523574458,\n",
       " 0.9045488440787062,\n",
       " 0.9202087993348091,\n",
       " 0.9202087993348091,\n",
       " 0.915734526404494,\n",
       " 0.9403430275212271,\n",
       " 0.9395973153661746,\n",
       " 0.9313944816605969,\n",
       " 0.9433258761414373,\n",
       " 0.9410887396762797,\n",
       " 0.9522744220020675,\n",
       " 0.9395973153661746,\n",
       " 0.9395973153661746]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/25\n",
      " 768/5216 [===>..........................] - ETA: 1:32 - loss: 0.7138 - recall: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-becea40a5a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.0, nesterov=False),\n",
    "              metrics=[keras_metrics.recall()])\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=25,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.history['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1, momentum=0.0, nesterov=False),\n",
    "              metrics=[keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_31_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-889bcb29125f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=2)\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_31_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=25,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_51_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-726e9a8f32b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_51_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_41_input to have 2 dimensions, but got array with shape (624, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f92842fd7541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_41_input to have 2 dimensions, but got array with shape (624, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027672075449726174, 0.9992542877703762]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.213027333601927, 0.40170940153773105]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "rec = history.history['recall']\n",
    "val_rec = history.history['val_recall']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(rec))\n",
    "plt.plot(epochs, rec, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_rec, 'r', label='Validation acc')\n",
    "plt.title('Training and validation Recall')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                        input_shape=(128,128,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "5216/5216 [==============================] - 44s 8ms/step - loss: 0.5778 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.7966 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=1,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 15s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5725939910104669, 0.0, 0.0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6894019811581342, 0.0, 0.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 60, 60, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                802880    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 830,113\n",
      "Trainable params: 830,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
