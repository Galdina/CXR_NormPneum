{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/viviandang/opt/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/viviandang/opt/anaconda3/lib/python3.7/site-packages (4.2.0.34)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/viviandang/opt/anaconda3/lib/python3.7/site-packages (from opencv-python) (1.17.2)\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "!{sys.executable} -m pip install opencv-python\n",
    "\n",
    "import time\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATADIR = 'data/Train/'\n",
    "# CATEGORIES = ['NORMAL', 'PNEUMONIA']\n",
    "# for category in CATEGORIES:\n",
    "#     path = os.path.join(DATADIR, category)\n",
    "#     for img in os.listdir(path):\n",
    "#         img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "#         plt.imshow(img_array,)\n",
    "#         plt.show()\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create path to folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale and Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import scipy\n",
    "# import numpy as np\n",
    "# from PIL import Image\n",
    "# from scipy import ndimage\n",
    "# from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "# np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = 'data/test'\n",
    "train_folder = 'data/train'\n",
    "val_folder = 'data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# get all the data in the directory split/test (180 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_folder, \n",
    "        target_size=(64, 64), batch_size = 624 ) \n",
    "\n",
    "# get all the data in the directory split/validation (200 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_folder, \n",
    "        target_size=(64, 64), batch_size = 16)\n",
    "\n",
    "# get all the data in the directory split/train (542 images), and reshape them\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(train_folder, \n",
    "        target_size=(64, 64), batch_size = 5216)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 5216\n",
      "Number of testing samples: 624\n",
      "Number of validation samples: 16\n",
      "train_images shape: (5216, 64, 64, 3)\n",
      "train_labels shape: (5216, 2)\n",
      "test_images shape: (624, 64, 64, 3)\n",
      "test_labels shape: (624, 2)\n",
      "val_images shape: (16, 64, 64, 3)\n",
      "val_labels shape: (16, 2)\n"
     ]
    }
   ],
   "source": [
    "# Explore your dataset again\n",
    "m_train = train_images.shape[0]\n",
    "num_px = train_images.shape[1]\n",
    "m_test = test_images.shape[0]\n",
    "m_val = val_images.shape[0]\n",
    "\n",
    "print (\"Number of training samples: \" + str(m_train))\n",
    "print (\"Number of testing samples: \" + str(m_test))\n",
    "print (\"Number of validation samples: \" + str(m_val))\n",
    "print (\"train_images shape: \" + str(train_images.shape))\n",
    "print (\"train_labels shape: \" + str(train_labels.shape))\n",
    "print (\"test_images shape: \" + str(test_images.shape))\n",
    "print (\"test_labels shape: \" + str(test_labels.shape))\n",
    "print (\"val_images shape: \" + str(val_images.shape))\n",
    "print (\"val_labels shape: \" + str(val_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5216, 12288)\n",
      "(624, 12288)\n",
      "(16, 12288)\n"
     ]
    }
   ],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "print(train_img.shape)\n",
    "print(test_img.shape)\n",
    "print(val_img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating X-y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a baseline model (fully connected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a baseline fully connected model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "np.random.seed(123)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(20, activation='relu', input_shape=(12288,))) # 2 hidden layers\n",
    "model.add(layers.Dense(7, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(5, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras_metrics'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2d5eb6bb96c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_metrics'"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/50\n",
      "5216/5216 [==============================] - 2s 327us/step - loss: 0.1403 - acc: 0.9567 - f1_m: 0.8847 - precision_m: 0.9164 - recall_m: 0.8769 - val_loss: 0.4874 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 2/50\n",
      "5216/5216 [==============================] - 1s 172us/step - loss: 0.1371 - acc: 0.9597 - f1_m: 0.8972 - precision_m: 0.9382 - recall_m: 0.8804 - val_loss: 0.3598 - val_acc: 0.9375 - val_f1_m: 0.9333 - val_precision_m: 1.0000 - val_recall_m: 0.8750\n",
      "Epoch 3/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1458 - acc: 0.9576 - f1_m: 0.8952 - precision_m: 0.9367 - recall_m: 0.8780 - val_loss: 0.2350 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 4/50\n",
      "5216/5216 [==============================] - 1s 165us/step - loss: 0.1384 - acc: 0.9578 - f1_m: 0.8918 - precision_m: 0.9378 - recall_m: 0.8755 - val_loss: 0.4537 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 5/50\n",
      "5216/5216 [==============================] - 1s 165us/step - loss: 0.1316 - acc: 0.9617 - f1_m: 0.9073 - precision_m: 0.9357 - recall_m: 0.8999 - val_loss: 0.3673 - val_acc: 0.9375 - val_f1_m: 0.9333 - val_precision_m: 1.0000 - val_recall_m: 0.8750\n",
      "Epoch 6/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1271 - acc: 0.9617 - f1_m: 0.9009 - precision_m: 0.9317 - recall_m: 0.8919 - val_loss: 0.4710 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 7/50\n",
      "5216/5216 [==============================] - 1s 164us/step - loss: 0.1529 - acc: 0.9540 - f1_m: 0.8937 - precision_m: 0.9395 - recall_m: 0.8757 - val_loss: 0.3663 - val_acc: 0.9375 - val_f1_m: 0.9333 - val_precision_m: 1.0000 - val_recall_m: 0.8750\n",
      "Epoch 8/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1450 - acc: 0.9555 - f1_m: 0.8891 - precision_m: 0.9283 - recall_m: 0.8721 - val_loss: 0.4500 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 9/50\n",
      "5216/5216 [==============================] - 1s 164us/step - loss: 0.1365 - acc: 0.9590 - f1_m: 0.9033 - precision_m: 0.9349 - recall_m: 0.8962 - val_loss: 0.4168 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 10/50\n",
      "5216/5216 [==============================] - 1s 170us/step - loss: 0.1347 - acc: 0.9588 - f1_m: 0.8955 - precision_m: 0.9332 - recall_m: 0.8823 - val_loss: 0.4927 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 11/50\n",
      "5216/5216 [==============================] - 1s 164us/step - loss: 0.1324 - acc: 0.9594 - f1_m: 0.8956 - precision_m: 0.9331 - recall_m: 0.8836 - val_loss: 0.7716 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 12/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1566 - acc: 0.9517 - f1_m: 0.8842 - precision_m: 0.9312 - recall_m: 0.8768 - val_loss: 0.4283 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 13/50\n",
      "5216/5216 [==============================] - 1s 172us/step - loss: 0.1495 - acc: 0.9542 - f1_m: 0.8915 - precision_m: 0.9327 - recall_m: 0.8819 - val_loss: 0.4536 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 14/50\n",
      "5216/5216 [==============================] - 1s 177us/step - loss: 0.1381 - acc: 0.9592 - f1_m: 0.8964 - precision_m: 0.9293 - recall_m: 0.8863 - val_loss: 0.3972 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 15/50\n",
      "5216/5216 [==============================] - 1s 216us/step - loss: 0.1334 - acc: 0.9599 - f1_m: 0.9026 - precision_m: 0.9410 - recall_m: 0.8922 - val_loss: 0.6239 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 16/50\n",
      "5216/5216 [==============================] - 1s 207us/step - loss: 0.1386 - acc: 0.9561 - f1_m: 0.8945 - precision_m: 0.9334 - recall_m: 0.8806 - val_loss: 0.3865 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 17/50\n",
      "5216/5216 [==============================] - 1s 213us/step - loss: 0.1541 - acc: 0.9546 - f1_m: 0.8885 - precision_m: 0.9411 - recall_m: 0.8662 - val_loss: 0.6227 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 18/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1405 - acc: 0.9563 - f1_m: 0.8884 - precision_m: 0.9268 - recall_m: 0.8763 - val_loss: 0.3971 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 19/50\n",
      "5216/5216 [==============================] - 1s 185us/step - loss: 0.1421 - acc: 0.9574 - f1_m: 0.8937 - precision_m: 0.9357 - recall_m: 0.8772 - val_loss: 0.5148 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 20/50\n",
      "5216/5216 [==============================] - 1s 182us/step - loss: 0.1448 - acc: 0.9551 - f1_m: 0.8817 - precision_m: 0.9184 - recall_m: 0.8697 - val_loss: 0.3591 - val_acc: 0.9375 - val_f1_m: 0.9333 - val_precision_m: 1.0000 - val_recall_m: 0.8750\n",
      "Epoch 21/50\n",
      "5216/5216 [==============================] - 1s 185us/step - loss: 0.1375 - acc: 0.9586 - f1_m: 0.9025 - precision_m: 0.9458 - recall_m: 0.8862 - val_loss: 0.4854 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 22/50\n",
      "5216/5216 [==============================] - 1s 173us/step - loss: 0.1590 - acc: 0.9509 - f1_m: 0.8837 - precision_m: 0.9301 - recall_m: 0.8679 - val_loss: 0.4151 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 23/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1401 - acc: 0.9586 - f1_m: 0.8996 - precision_m: 0.9374 - recall_m: 0.8866 - val_loss: 0.4275 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 24/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1461 - acc: 0.9588 - f1_m: 0.8976 - precision_m: 0.9366 - recall_m: 0.8831 - val_loss: 0.5139 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 25/50\n",
      "5216/5216 [==============================] - 1s 167us/step - loss: 0.1288 - acc: 0.9622 - f1_m: 0.8987 - precision_m: 0.9282 - recall_m: 0.8929 - val_loss: 0.3978 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 26/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1317 - acc: 0.9620 - f1_m: 0.9076 - precision_m: 0.9481 - recall_m: 0.8927 - val_loss: 0.3907 - val_acc: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 1.0000 - val_recall_m: 0.7500\n",
      "Epoch 27/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1318 - acc: 0.9611 - f1_m: 0.9021 - precision_m: 0.9462 - recall_m: 0.8826 - val_loss: 0.5427 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 28/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1425 - acc: 0.9565 - f1_m: 0.8887 - precision_m: 0.9259 - recall_m: 0.8799 - val_loss: 0.5346 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 29/50\n",
      "5216/5216 [==============================] - 1s 173us/step - loss: 0.1369 - acc: 0.9561 - f1_m: 0.8941 - precision_m: 0.9329 - recall_m: 0.8801 - val_loss: 0.4457 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 30/50\n",
      "5216/5216 [==============================] - 1s 170us/step - loss: 0.1316 - acc: 0.9605 - f1_m: 0.8979 - precision_m: 0.9360 - recall_m: 0.8852 - val_loss: 0.2568 - val_acc: 0.8750 - val_f1_m: 0.8750 - val_precision_m: 0.8750 - val_recall_m: 0.8750\n",
      "Epoch 31/50\n",
      "5216/5216 [==============================] - 1s 172us/step - loss: 0.1399 - acc: 0.9603 - f1_m: 0.9038 - precision_m: 0.9415 - recall_m: 0.8911 - val_loss: 0.3975 - val_acc: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 1.0000 - val_recall_m: 0.7500\n",
      "Epoch 32/50\n",
      "5216/5216 [==============================] - 1s 167us/step - loss: 0.1378 - acc: 0.9572 - f1_m: 0.8928 - precision_m: 0.9249 - recall_m: 0.8882 - val_loss: 0.4145 - val_acc: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 1.0000 - val_recall_m: 0.7500\n",
      "Epoch 33/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1275 - acc: 0.9615 - f1_m: 0.8998 - precision_m: 0.9425 - recall_m: 0.8837 - val_loss: 0.4059 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 34/50\n",
      "5216/5216 [==============================] - 1s 165us/step - loss: 0.1373 - acc: 0.9597 - f1_m: 0.8999 - precision_m: 0.9479 - recall_m: 0.8769 - val_loss: 0.4508 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 35/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1369 - acc: 0.9578 - f1_m: 0.9063 - precision_m: 0.9361 - recall_m: 0.9007 - val_loss: 0.4240 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 36/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1245 - acc: 0.9647 - f1_m: 0.9042 - precision_m: 0.9444 - recall_m: 0.8890 - val_loss: 0.4433 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 37/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1341 - acc: 0.9592 - f1_m: 0.8943 - precision_m: 0.9307 - recall_m: 0.8794 - val_loss: 0.4295 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 38/50\n",
      "5216/5216 [==============================] - 1s 167us/step - loss: 0.1335 - acc: 0.9607 - f1_m: 0.8973 - precision_m: 0.9341 - recall_m: 0.8852 - val_loss: 0.3930 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 39/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1241 - acc: 0.9626 - f1_m: 0.9044 - precision_m: 0.9418 - recall_m: 0.8912 - val_loss: 0.7931 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 40/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1250 - acc: 0.9626 - f1_m: 0.9034 - precision_m: 0.9351 - recall_m: 0.8924 - val_loss: 0.4212 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 41/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1290 - acc: 0.9638 - f1_m: 0.8931 - precision_m: 0.9313 - recall_m: 0.8766 - val_loss: 0.4774 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 42/50\n",
      "5216/5216 [==============================] - 1s 167us/step - loss: 0.1249 - acc: 0.9626 - f1_m: 0.9023 - precision_m: 0.9344 - recall_m: 0.8954 - val_loss: 0.5087 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 43/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1271 - acc: 0.9634 - f1_m: 0.9117 - precision_m: 0.9539 - recall_m: 0.8919 - val_loss: 0.4220 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "Epoch 44/50\n",
      "5216/5216 [==============================] - 1s 166us/step - loss: 0.1331 - acc: 0.9594 - f1_m: 0.8950 - precision_m: 0.9372 - recall_m: 0.8805 - val_loss: 0.3436 - val_acc: 0.9375 - val_f1_m: 0.9333 - val_precision_m: 1.0000 - val_recall_m: 0.8750\n",
      "Epoch 45/50\n",
      "5216/5216 [==============================] - 1s 168us/step - loss: 0.1232 - acc: 0.9670 - f1_m: 0.9117 - precision_m: 0.9497 - recall_m: 0.8944 - val_loss: 0.3827 - val_acc: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 1.0000 - val_recall_m: 0.7500\n",
      "Epoch 46/50\n",
      "5216/5216 [==============================] - 1s 170us/step - loss: 0.1209 - acc: 0.9659 - f1_m: 0.9170 - precision_m: 0.9497 - recall_m: 0.9048 - val_loss: 0.8590 - val_acc: 0.6875 - val_f1_m: 0.5455 - val_precision_m: 1.0000 - val_recall_m: 0.3750\n",
      "Epoch 47/50\n",
      "5216/5216 [==============================] - 1s 175us/step - loss: 0.1212 - acc: 0.9636 - f1_m: 0.9215 - precision_m: 0.9591 - recall_m: 0.9061 - val_loss: 0.3702 - val_acc: 0.8750 - val_f1_m: 0.8571 - val_precision_m: 1.0000 - val_recall_m: 0.7500\n",
      "Epoch 48/50\n",
      "5216/5216 [==============================] - 1s 169us/step - loss: 0.1345 - acc: 0.9607 - f1_m: 0.9058 - precision_m: 0.9483 - recall_m: 0.8881 - val_loss: 0.3467 - val_acc: 0.9375 - val_f1_m: 0.9333 - val_precision_m: 1.0000 - val_recall_m: 0.8750\n",
      "Epoch 49/50\n",
      "5216/5216 [==============================] - 1s 172us/step - loss: 0.1225 - acc: 0.9636 - f1_m: 0.9167 - precision_m: 0.9527 - recall_m: 0.9047 - val_loss: 0.5071 - val_acc: 0.7500 - val_f1_m: 0.6667 - val_precision_m: 1.0000 - val_recall_m: 0.5000\n",
      "Epoch 50/50\n",
      "5216/5216 [==============================] - 1s 170us/step - loss: 0.1197 - acc: 0.9659 - f1_m: 0.9058 - precision_m: 0.9413 - recall_m: 0.8901 - val_loss: 0.4012 - val_acc: 0.8125 - val_f1_m: 0.7692 - val_precision_m: 1.0000 - val_recall_m: 0.6250\n",
      "624/624 [==============================] - 0s 95us/step\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc',f1_m,precision_m, recall_m])\n",
    "\n",
    "histoire = model.fit(train_img,\n",
    "                    train_y,\n",
    "                    epochs=50,\n",
    "                    batch_size=16,\n",
    "                    validation_data=(val_img, val_y), verbose = 1)\n",
    "\n",
    "# evaluate the model\n",
    "loss, accuracy, f1_score, precision, recall = model.evaluate(test_img, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41661950945854187"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9509993592898051 0.7419871687889099 0.48266419768333435 0.9624999761581421 0.33071663975715637\n"
     ]
    }
   ],
   "source": [
    "print(loss, accuracy, f1_score, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = model.evaluate(train_img, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val = model.evaluate(val_img, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
