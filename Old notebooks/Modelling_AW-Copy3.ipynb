{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "import keras_metrics\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras_metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV \n",
    "\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder = '../data/test'\n",
    "train_folder = '../data/train'\n",
    "val_folder = '../data/val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n",
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        test_folder, \n",
    "        target_size=(64,64), batch_size = 627) \n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        val_folder, \n",
    "        target_size=(64,64), batch_size = 19)\n",
    "\n",
    "train_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
    "        train_folder, \n",
    "        target_size=(64,64), batch_size=5219)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, train_labels = next(train_generator)\n",
    "test_images, test_labels = next(test_generator)\n",
    "val_images, val_labels = next(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = train_images.reshape(train_images.shape[0], -1)\n",
    "test_img = test_images.reshape(test_images.shape[0], -1)\n",
    "val_img = val_images.reshape(val_images.shape[0], -1)\n",
    "\n",
    "train_y = np.reshape(train_labels[:,0], (5216,1))\n",
    "test_y = np.reshape(test_labels[:,0], (624,1))\n",
    "val_y = np.reshape(val_labels[:,0], (16,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5216, 12288)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(6, (3, 3), activation='relu',\n",
    "                        input_shape=(64 ,64,  3)))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=3))\n",
    "model.add(layers.Dropout(0.75))  \n",
    "\n",
    "model.add(layers.Conv2D(12, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=3))\n",
    "model.add(layers.Dropout(0.05))  \n",
    "\n",
    "model.add(layers.Conv2D(18, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((3, 3), strides=3))\n",
    "model.add(layers.Dropout(0.0025)) \n",
    "\n",
    "#model.add(layers.Conv2D(24,(3, 3),  activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((3, 3), strides=3))\n",
    "#model.add(layers.Dropout(0.0125)) \n",
    "\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "# model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "# confusion matrx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/10\n",
      "5216/5216 [==============================] - 5s 991us/step - loss: 0.5679 - acc: 0.7429 - recall: 0.0060 - val_loss: 0.7053 - val_acc: 0.5000 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "5216/5216 [==============================] - 4s 815us/step - loss: 0.4950 - acc: 0.7646 - recall: 0.1253 - val_loss: 0.6721 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 3/10\n",
      "5216/5216 [==============================] - 4s 820us/step - loss: 0.3930 - acc: 0.8188 - recall: 0.4750 - val_loss: 0.5803 - val_acc: 0.6875 - val_recall: 0.8750\n",
      "Epoch 4/10\n",
      "5216/5216 [==============================] - 6s 1ms/step - loss: 0.3489 - acc: 0.8428 - recall: 0.6010 - val_loss: 0.5424 - val_acc: 0.8125 - val_recall: 0.8750\n",
      "Epoch 5/10\n",
      "5216/5216 [==============================] - 7s 1ms/step - loss: 0.3318 - acc: 0.8518 - recall: 0.6465 - val_loss: 0.5266 - val_acc: 0.7500 - val_recall: 0.7500\n",
      "Epoch 6/10\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.3197 - acc: 0.8551 - recall: 0.6592 - val_loss: 0.5481 - val_acc: 0.7500 - val_recall: 0.7500\n",
      "Epoch 7/10\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.3065 - acc: 0.8664 - recall: 0.6913 - val_loss: 0.5363 - val_acc: 0.7500 - val_recall: 0.6250\n",
      "Epoch 8/10\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.3044 - acc: 0.8622 - recall: 0.6756 - val_loss: 0.5893 - val_acc: 0.6250 - val_recall: 0.2500\n",
      "Epoch 9/10\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.2969 - acc: 0.8664 - recall: 0.6898 - val_loss: 0.5198 - val_acc: 0.8125 - val_recall: 0.7500\n",
      "Epoch 10/10\n",
      "5216/5216 [==============================] - 9s 2ms/step - loss: 0.2800 - acc: 0.8767 - recall: 0.7286 - val_loss: 0.5356 - val_acc: 0.7500 - val_recall: 0.5000\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc',keras_metrics.recall()])\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 5s 898us/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 1s 913us/step\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4111817696708843, 0.8767254601226994, 0.9604772557076452]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45350583700033337, 0.8461538461538461, 0.799145298803784]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6838180461831604,\n",
       " 0.8523489932250299,\n",
       " 0.8724832214114479,\n",
       " 0.9023117076135486,\n",
       " 0.9127516777842839]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_classes(val_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [0., 1.],\n",
       "       [0., 1.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.],\n",
       "       [1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/25\n",
      " 768/5216 [===>..........................] - ETA: 1:32 - loss: 0.7138 - recall: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-becea40a5a85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                     verbose=1)\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2719\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2720\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2721\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2693\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2694\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1137\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1353\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1355\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1356\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1359\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1361\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1338\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[0;32m-> 1340\u001b[0;31m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.0, nesterov=False),\n",
    "              metrics=[keras_metrics.recall()])\n",
    "\n",
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=25,\n",
    "                    batch_size=64,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#history.history['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.SGD(lr=0.1, momentum=0.0, nesterov=False),\n",
    "              metrics=[keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_31_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-889bcb29125f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                     verbose=2)\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_31_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=25,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_51_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-726e9a8f32b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_51_input to have 2 dimensions, but got array with shape (5216, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_41_input to have 2 dimensions, but got array with shape (624, 64, 64, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-f92842fd7541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/learn-env/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    129\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_41_input to have 2 dimensions, but got array with shape (624, 64, 64, 3)"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.027672075449726174, 0.9992542877703762]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.213027333601927, 0.40170940153773105]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "rec = history.history['recall']\n",
    "val_rec = history.history['val_recall']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(rec))\n",
    "plt.plot(epochs, rec, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_rec, 'r', label='Validation acc')\n",
    "plt.title('Training and validation Recall')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3, 3), activation='relu',\n",
    "                        input_shape=(128,128,  3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(32, (4, 4), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"sgd\",\n",
    "              metrics=[keras_metrics.precision(), keras_metrics.recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5216 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "5216/5216 [==============================] - 44s 8ms/step - loss: 0.5778 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.7966 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images,\n",
    "                    train_y,\n",
    "                    epochs=1,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(val_images, val_y),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5216/5216 [==============================] - 15s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_images, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "624/624 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "results_test = model.evaluate(test_images, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5725939910104669, 0.0, 0.0]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6894019811581342, 0.0, 0.0]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_20 (Conv2D)           (None, 126, 126, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 63, 63, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 60, 60, 32)        8224      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 30, 30, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 64)                802880    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 830,113\n",
      "Trainable params: 830,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
